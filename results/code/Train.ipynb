{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkW3IxYQmNiV"
      },
      "outputs": [],
      "source": [
        "!pip install music21\n",
        "!pip install mido\n",
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pretty_midi\n",
        "from music21 import *\n",
        "import numpy as np\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "from itertools import groupby\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit([np.arange(128).tolist()])\n",
        "\n",
        "encoded_data_path = \"/content/drive/MyDrive/encoded_doug_mckenzie_midi_16_v2/encoded_doug_mckenzie_midi_16_v2/\"\n",
        "output_path = \"./output/\"\n",
        "\n",
        "batch_size = 32\n",
        "sequence_length = 300\n",
        "generate_sample_every_ep = 100\n",
        "\n",
        "maxlen = sequence_length  # Max sequence size\n",
        "\n",
        "embed_dim = 128  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "feed_forward_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "combi_to_int_pickle = \"combi_to_int.pickle\"\n",
        "int_to_combi_pickle = \"int_to_combi.pickle\"\n",
        "vocab_pickle = \"vocab.pickle\"\n",
        "\n",
        "vocab_size = 40000\n",
        "unk_tag_str = '<UNK>'\n",
        "unk_tag_idx = 0\n",
        "pad_tag_str = ''\n",
        "pad_tag_idx = 1"
      ],
      "metadata": {
        "id": "bQ3QyQAnmTTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_songs = []\n",
        "# all_song_in_tuple = []\n",
        "all_songs_np = np.empty((0,128), np.int8)\n",
        "for temp in glob.glob(encoded_data_path + \"*.npy\"):\n",
        "    encoded_data = np.load(temp).astype(np.int8)\n",
        "    print(encoded_data.shape)\n",
        "    all_songs.append(encoded_data)\n",
        "    all_songs_np = np.append(all_songs_np, encoded_data, axis=0)\n"
      ],
      "metadata": {
        "id": "Ux5-usnhmq98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_songs_np.shape)\n",
        "unique_np, counts = np.unique(all_songs_np, axis=0, return_counts=True)\n",
        "\n",
        "unique_note_intergerized = np.array(mlb.inverse_transform(unique_np))\n",
        "count_sort_ind = np.argsort(-counts)\n",
        "\n",
        "vocab = unique_note_intergerized[count_sort_ind][:vocab_size-2].tolist()\n",
        "top_counts = counts[count_sort_ind][:vocab_size-1].tolist()\n",
        "# vocab.insert(unk_tag_idx, unk_tag_str)\n",
        "\n",
        "vocab.sort(key=len)\n",
        "# vocab = unique_note_intergerized\n",
        "vocab.insert(unk_tag_idx, unk_tag_str)\n",
        "vocab.insert(pad_tag_idx, pad_tag_str)\n",
        "vocab_size = len(vocab)\n",
        "# vocab_size = 54000\n",
        "print(f\"vocab size: {len(vocab)}\")\n",
        "print(f\"vocab first 5 words: {vocab[:5]}\")"
      ],
      "metadata": {
        "id": "sfCvJBxYmuZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combi_to_int = dict((combi, number) for number, combi in enumerate(vocab))\n",
        "int_to_combi = dict((number, combi) for number, combi in enumerate(vocab))\n",
        "\n",
        "all_song_tokenised = []\n",
        "for idx, song in enumerate(all_songs):\n",
        "    print(f\"processing song number {idx}\")\n",
        "    song = mlb.inverse_transform(song)\n",
        "    song = [combi_to_int[tup] if tup in vocab else unk_tag_idx for tup in song]\n",
        "#     song = [combi_to_int[tup] for tup in song]\n",
        "    all_song_tokenised.append(np.array(song))\n",
        "print(f\"Completed tokenising all song\")\n",
        "\n",
        "#delete to free up memory\n",
        "del all_songs\n",
        "del all_songs_np\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "_kStDbCzmwAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "#         self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.maxlen = maxlen\n",
        "        self.maximum_position_encoding = 10000\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'maxlen': self.maxlen,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "        return pos * angle_rates\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n",
        "                              np.arange(d_model)[np.newaxis, :],\n",
        "                              d_model)\n",
        "\n",
        "        # apply sin to even indices in the array; 2i\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "        # apply cos to odd indices in the array; 2i+1\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        pos_encoding = self.positional_encoding(self.maximum_position_encoding, self.embed_dim)\n",
        "        x = self.token_emb(x)\n",
        "        return x + pos_encoding[:,:maxlen,:]\n"
      ],
      "metadata": {
        "id": "sdWyjKc4m1a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        #defining no of nodes/dim for each layer\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'num_heads': self.num_heads,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @staticmethod\n",
        "    def causal_attention_mask(n_dest, n_src, dtype):\n",
        "        \"\"\"\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        return tf.cast(m, dtype)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "\n",
        "        # prevent information flow from future tokens\n",
        "        shape = tf.shape(scaled_score)\n",
        "        dim_dest, dim_src = shape[2], shape[3]\n",
        "        attention_mask = self.causal_attention_mask(\n",
        "            dim_dest, dim_src, scaled_score.dtype\n",
        "        )\n",
        "        attention_mask = tf.reshape(attention_mask, [1, 1, dim_dest, dim_src])\n",
        "        scaled_score = scaled_score * attention_mask - 1e4 * (1 - attention_mask)\n",
        "\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ],
      "metadata": {
        "id": "0RV6RhN5m3HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'num_heads': self.num_heads,\n",
        "            'ff_dim': self.ff_dim,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention_output = self.att(inputs)\n",
        "        attention_output = self.dropout1(attention_output)\n",
        "        out1 = self.layernorm1(inputs + attention_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "4tYWtP5Lm4vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "def create_model():\n",
        "    inputs = layers.Input(shape=(maxlen,), dtype=tf.int32)\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block1 = TransformerBlock(embed_dim, num_heads, feed_forward_dim, dropout_rate = 0.25)\n",
        "    transformer_block2 = TransformerBlock(embed_dim, num_heads, feed_forward_dim, dropout_rate = 0.25)\n",
        "    transformer_block3 = TransformerBlock(embed_dim, num_heads, feed_forward_dim, dropout_rate = 0.25)\n",
        "    x = transformer_block1(x)\n",
        "    x = transformer_block2(x)\n",
        "    x = transformer_block3(x)\n",
        "    outputs = layers.Dense(vocab_size)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=[outputs, x])\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(\n",
        "        \"adam\", loss=[loss_fn, None],\n",
        "    )  # No loss and optimization based on word embeddings from transformer block\n",
        "    return model"
      ],
      "metadata": {
        "id": "nL-4PLOWm6MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "W5F48tOFm7jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Custom_Generator(keras.utils.Sequence) :\n",
        "    def __init__(self, all_song_tokenised, batch_size, sequence_length, val_split = 0, shuffle=True) :\n",
        "        self.all_song_tokenised = all_song_tokenised\n",
        "        self.pad_tag_idx = 1\n",
        "        self.sequence_length = sequence_length\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.val_split = val_split\n",
        "        if(self.val_split != 0):\n",
        "            self.all_song_tokenised = random.choices(self.all_song_tokenised, k = int(self.val_split*len(self.all_song_tokenised)))\n",
        "            self.batch_size = len(self.all_song_tokenised)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self) :\n",
        "#         return (np.ceil((len(self.pickle_filenames)* self.data_per_file)/ float(self.batch_size))).astype(np.int)\n",
        "        return int(np.ceil(len(self.all_song_tokenised)/ self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.all_song_tokenised)\n",
        "\n",
        "    def __getitem__(self, idx) :\n",
        "        batch_x = np.empty((0, self.sequence_length), float)\n",
        "        batch_y = np.empty((0, self.sequence_length), float)\n",
        "        for i in range(self.batch_size):\n",
        "            if(idx*self.batch_size + i == len(self.all_song_tokenised)-1):\n",
        "                return batch_x, batch_y\n",
        "            song = self.all_song_tokenised[idx*self.batch_size + i]\n",
        "            start_idx = random.randint(0,len(song) - self.sequence_length/2)\n",
        "            seq = song[start_idx: start_idx + self.sequence_length + 1]\n",
        "            x= seq[:-1]\n",
        "            y = seq[1:]\n",
        "#           padding if needed\n",
        "            if(len(y) < self.sequence_length):\n",
        "                no_of_pad = self.sequence_length - len(y)\n",
        "                x = np.append(x, [self.pad_tag_idx]*no_of_pad, axis = 0)\n",
        "                y = np.append(y, [self.pad_tag_idx]*no_of_pad, axis = 0)\n",
        "#             print(idx*batch_size + i)\n",
        "#             while (np.unique(seq).shape[0] == 1):\n",
        "#                 start_idx = random.randint(0,len(song) - self.sequence_length-2)\n",
        "#                 seq = song[start_idx: start_idx + self.sequence_length + 1]\n",
        "\n",
        "            batch_x = np.append(batch_x, [x], axis = 0)\n",
        "            batch_y = np.append(batch_y, [y], axis = 0)\n",
        "\n",
        "        return batch_x, batch_y"
      ],
      "metadata": {
        "id": "GznJpTUUm-iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GeneratorCallback(keras.callbacks.Callback):\n",
        "    \"\"\"Callback to generate text from trained model.\n",
        "    1. Feed some starting prompt to the model\n",
        "    2. Predict probabilities for next token\n",
        "    3. Sample next token and add it to the next input\n",
        "\n",
        "    # Arguments\n",
        "        max_tokens: Integer, the number of tokens to be generated after prompt.\n",
        "        start_tokens: List of integers, the token indices for the starting prompt.\n",
        "        index_to_word: List of strings, obtained from TextVectorization layer.\n",
        "        top_k: Integer, sample from the `top_k` token predictions.\n",
        "        print_every: Integer, print after this many epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, max_tokens, start_tokens, top_k=10, print_every=5\n",
        "    ):\n",
        "        self.max_tokens = max_tokens\n",
        "        self.start_tokens = start_tokens\n",
        "#         self.index_to_word = index_to_word\n",
        "        self.print_every = print_every\n",
        "        self.k = top_k\n",
        "\n",
        "    def sample_from(self, logits):\n",
        "        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n",
        "        indices = np.asarray(indices).astype(\"int32\")\n",
        "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
        "        preds = np.asarray(preds).astype(\"float32\")\n",
        "        return np.random.choice(indices, p=preds)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        start_tokens = [_ for _ in self.start_tokens]\n",
        "        if (epoch + 1) % self.print_every != 0:\n",
        "            return\n",
        "        num_tokens_generated = 0\n",
        "        tokens_generated = []\n",
        "        while num_tokens_generated <= self.max_tokens:\n",
        "            x = start_tokens[-sequence_length:]\n",
        "            pad_len = maxlen - len(start_tokens)\n",
        "            sample_index = -1\n",
        "            if pad_len > 0:\n",
        "                x = start_tokens + [0] * pad_len\n",
        "                sample_index = len(start_tokens) - 1\n",
        "\n",
        "            x = np.array([x])\n",
        "            y, _ = self.model.predict(x)\n",
        "            sample_token = self.sample_from(y[0][sample_index])\n",
        "            tokens_generated.append(sample_token)\n",
        "            start_tokens.append(sample_token)\n",
        "            num_tokens_generated = len(tokens_generated)\n",
        "\n",
        "#         txt = \" \".join(\n",
        "#             [self.detokenize(_) for _ in self.start_tokens + tokens_generated]\n",
        "#         )\n",
        "\n",
        "        print(f\"last 40 tokens of starting token:\\n{self.start_tokens[-50:]}\\n\")\n",
        "        print(f\"generated token:\\n{tokens_generated}\\n\")\n",
        "\n",
        "start_tokens = all_song_tokenised[1][:sequence_length-200]\n",
        "num_tokens_generated = 80\n",
        "gen_callback = GeneratorCallback(num_tokens_generated, start_tokens, print_every= generate_sample_every_ep)"
      ],
      "metadata": {
        "id": "nwgTldium_tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1500\n",
        "batchsize = 32\n",
        "output_path = f\"./output/MuGenTransformer_v3_{epochs}{batchsize}{int(time.time())}_16v2f/\"\n",
        "\n",
        "\n",
        "my_training_batch_generator = My_Custom_Generator(all_song_tokenised, batchsize, sequence_length)\n",
        "my_validation_batch_generator = My_Custom_Generator(all_song_tokenised, batchsize, sequence_length, val_split=0.1)\n",
        "\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "    os.mkdir(output_path)\n",
        "\n",
        "# model.load_weights(\"./output/train_multilabel_v3_1_4001000_16th/music-gen-weight.hdf5\")\n",
        "\n",
        "weight_path = output_path + \"music-gen-weight.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    weight_path,\n",
        "    monitor='loss',\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "callbacks_list = [checkpoint,gen_callback]\n",
        "# history = model.fit(network_input,\n",
        "#                     network_output,\n",
        "#                     epochs=epochs,\n",
        "#                     batch_size=batchsize,\n",
        "#                     callbacks=callbacks_list,\n",
        "#                     validation_split=0.1,\n",
        "#                    shuffle=True)\n",
        "\n",
        "history = model.fit(x = my_training_batch_generator,\n",
        "                    callbacks = callbacks_list,\n",
        "                   epochs = epochs,\n",
        "                   verbose = 1,\n",
        "                   validation_data = my_validation_batch_generator)\n",
        "\n",
        "train_loss += history.history['loss']\n",
        "val_loss += history.history['val_loss']\n",
        "\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.title('model train vs validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'validation_loss'], loc='upper right')\n",
        "plt.savefig(output_path + 'loss.png')\n",
        "plt.show()\n",
        "print(\"Result stored in {}\".format(output_path))"
      ],
      "metadata": {
        "id": "rjlbekZDnBIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('./MuGenTransformer')\n"
      ],
      "metadata": {
        "id": "VRZtQDQznPP6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}